# -*- coding: utf-8 -*-
"""NovalAlgorithmWeb APP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQYTHRDJov_TKXmNMrW504jW56u8ILkA
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor
from sklearn.svm import SVC
import pickle

!pip install streamlit

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Load the saved models and preprocessor
try:
    # Update this path to point to your file in Google Drive
    file_path ='/content/drive/MyDrive/SAV files/all_models_and_preprocessor.sav'
    with open(file_path, 'rb') as file:
        models_and_preprocessor = pickle.load(file)
except FileNotFoundError as e:
    st.error(f"File not found: {e}")
    st.stop()
except UnicodeDecodeError as e:
    st.error(f"Error loading file: {e}")
    st.stop()

# Extract the models and preprocessor
svm_rf_models = models_and_preprocessor['svm_rf_models']
rf_regressor = models_and_preprocessor['rf_regressor']
lr_model = models_and_preprocessor['lr_model']
preprocessor = models_and_preprocessor['preprocessor']

# Define the function to make predictions
def predict_outcome(pH_Reading, Ec_Reading, P_Reading, K_Reading, Texture_Reading, OM_Reading):
    le = LabelEncoder()
    le.fit(['Sand', 'Loam', 'Clay'])  # Replace with your actual texture classes

    if Texture_Reading in le.classes_:
        Texture_Reading_encoded = le.transform([Texture_Reading])[0]
    else:
        Texture_Reading_encoded = 0

        new_data = pd.DataFrame({
        'pH Reading': [pH_Reading],
        'Ec Reading': [Ec_Reading],
        'P Reading': [P_Reading],
        'K Reading': [K_Reading],
        'Texture Reading': [Texture_Reading_encoded],
        'OM Reading': [OM_Reading]
    })

        new_data_scaled = preprocessor.transform(new_data)

    pred_classification = svm_rf_models.predict(new_data_scaled)
    pred_regression = rf_regressor.predict(new_data_scaled)
    pred_lr = lr_model.predict(new_data_scaled)

    # Assuming you have these targets defined elsewhere in your project
    classification_targets = ['pH Interpretation', 'pH Recommendation', 'Ec Interpretation', 'P Interpretation', 'P Recommendation', 'K Interpretation']  # Update with actual targets
    regression_targets = ['K Recommendation Percentage', 'OMRecommendationkgbyac']  # Update with actual targets

    pred_classification_df = pd.DataFrame(pred_classification, columns=classification_targets)
    pred_regression_df = pd.DataFrame(pred_regression, columns=regression_targets)
    pred_lr_df = pd.DataFrame(pred_lr, columns=['Texture Interpretation'])

    return pd.concat([pred_classification_df, pred_regression_df, pred_lr_df], axis=1)

import streamlit as st

# Streamlit interface
st.title("Hybrid Machine Learning Model Deployment")
# User inputs
pH_Reading = st.number_input('pH Reading', min_value=0.0)
Ec_Reading = st.number_input('Ec Reading', min_value=0.0)
P_Reading = st.number_input('P Reading', min_value=0.0)
K_Reading = st.number_input('K Reading', min_value=0.0)
Texture_Reading = st.selectbox('Texture Reading', ['Sand', 'Loam', 'Clay'])  # Replace with your actual options
OM_Reading = st.number_input('OM Reading', min_value=0.0)

if st.button('Predict'):
    predictions = predict_outcome(
        pH_Reading=pH_Reading,
        Ec_Reading=Ec_Reading,
        P_Reading=P_Reading,
        K_Reading=K_Reading,
        Texture_Reading=Texture_Reading,
        OM_Reading=OM_Reading
    )
    st.write(predictions)